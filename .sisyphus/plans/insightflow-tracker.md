# InsightFlow - AI ê¸°ìˆ  íŠ¸ë˜í‚¹ ì•± êµ¬ì¶• ê³„íš

## TL;DR

> **Quick Summary**: GitHub Actions ê¸°ë°˜ ì„œë²„ë¦¬ìŠ¤ AI ê¸°ìˆ  ë‰´ìŠ¤ íŠ¸ë˜ì»¤. GeekNews + Hacker Newsì—ì„œ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•˜ê³ , Gemini 2.0 Flashë¡œ í‚¤ì›Œë“œ í•„í„°ë§ + 3ì¤„ ìš”ì•½ì„ ìƒì„±í•œ ë’¤, í…”ë ˆê·¸ë¨ ë´‡ìœ¼ë¡œ ì¼ì¼ ë‹¤ì´ì œìŠ¤íŠ¸ë¥¼ ë°œì†¡í•©ë‹ˆë‹¤. ë°ì´í„°ëŠ” JSON íŒŒì¼ + GitHub Issuesì— ì €ì¥ë©ë‹ˆë‹¤.
>
> **Deliverables**:
> - ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„ë„ (Mermaid ë‹¤ì´ì–´ê·¸ë¨ í¬í•¨ README)
> - GitHub Actions ì›Œí¬í”Œë¡œìš° YAML (`daily-digest.yml`)
> - ëª¨ë“ˆí™”ëœ Python ì†ŒìŠ¤ ì½”ë“œ (6ê°œ ëª¨ë“ˆ)
> - ë¡œì»¬ í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì„± ê°€ì´ë“œ
> - ì¤‘ë³µ ìˆ˜ì§‘ ë°©ì§€ ë¡œì§ + ì‹¤íŒ¨ ì•Œë¦¼ ë©”ì»¤ë‹ˆì¦˜
>
> **Estimated Effort**: Medium (~2-3ì¼ êµ¬í˜„)
> **Parallel Execution**: YES - 3 waves
> **Critical Path**: Task 1 â†’ Task 2 â†’ Task 3 â†’ Task 4 â†’ Task 5 â†’ Task 6 â†’ Task 7 â†’ Task 8

---

## Context

### Original Request
ê°œë°œììš© AI ê¸°ìˆ  íŠ¸ë˜í‚¹ ì•± êµ¬ì¶•. ë‹¨ìˆœí•œ ì½”ë”©ì„ ë„˜ì–´ ì „ì²´ ì¸í”„ë¼ ì„¤ê³„ì™€ ë°°í¬ íŒŒì´í”„ë¼ì¸ì„ í¬í•¨í•˜ëŠ” ê°€ì´ë“œ. VPS ì—†ì´ GitHub Actionsë§Œìœ¼ë¡œ ë§¤ì¼ ì˜¤ì „ 8ì‹œ ìë™ ì‹¤í–‰. RSS/API ë°ì´í„° ìˆ˜ì§‘ â†’ LLM ìš”ì•½ â†’ í…”ë ˆê·¸ë¨ ë°œì†¡.

### Interview Summary
**Key Discussions**:
- Python 3.11 ì„ íƒ (ì•ˆì •ì„± + í˜¸í™˜ì„±)
- Gemini 2.0 Flash ë‹¨ë… ì‚¬ìš© (ë¬´ë£Œ í‹°ì–´: RPM 15, RPD 1,500)
- í•˜ì´ë¸Œë¦¬ë“œ í•„í„°ë§: í‚¤ì›Œë“œ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ 1ì°¨ â†’ Gemini 2ì°¨ ê´€ë ¨ì„± íŒë‹¨
- JSON + GitHub Issues ë³‘í–‰ ì €ì¥
- í…”ë ˆê·¸ë¨ ë´‡ìœ¼ë¡œ ì¼ì¼ ë‹¨ì¼ ë©”ì‹œì§€ ë°œì†¡
- GeekNews + Hacker News 2ê°œ ì†ŒìŠ¤ë§Œ (í™•ì¥ ê°€ëŠ¥ ì„¤ê³„)
- í…ŒìŠ¤íŠ¸ ì—†ìŒ (Agent QA ê²€ì¦)
- ê´€ì‹¬ í‚¤ì›Œë“œ: í’€ìŠ¤íƒ + ì¸í”„ë¼ (AI, LLM, React, TypeScript, Rust, Go, Docker, K8s, DevOps ë“±)

**Research Findings**:
- GitHub Actions cron `0 23 * * *` = KST ì˜¤ì „ 8ì‹œ (Â±5-15ë¶„ í¸ì°¨ ê°€ëŠ¥)
- Gemini ë¬´ë£Œ í‹°ì–´ 2025.12 ëŒ€í­ ì¶•ì†Œë¨ (gemini-2.0-flash: RPD 1,500)
- GeekNews Atom í”¼ë“œ: `https://news.hada.io/rss/news` (NOT `/rss` - 403 ë°œìƒ)
- HN API: `https://hacker-news.firebaseio.com/v0/` (ë°°ì¹˜ ë¯¸ì§€ì›, ê°œë³„ fetch í•„ìš”)
- ì°¸ì¡° í”„ë¡œì íŠ¸: `aastroza/rss-feeds-scraper` (GitHub Actions + JSON ìë™ì»¤ë°‹ íŒ¨í„´)

### Metis Review
**Identified Gaps** (addressed):
- **GeekNews RSS URL ì˜¤ë¥˜**: `/rss` â†’ `/rss/news`ë¡œ ìˆ˜ì • (403 ë°©ì§€)
- **GeekNews ì›ë³¸ URL ë¯¸í¬í•¨**: Atom í”¼ë“œì— ì›ë³¸ ê¸°ì‚¬ URL ì—†ìŒ â†’ í† í”½ í˜ì´ì§€ íŒŒì‹±ìœ¼ë¡œ í•´ê²°
- **Telegram 4,096 char ì œí•œ**: ë©”ì‹œì§€ ì²­í‚¹ ë¡œì§ ì¶”ê°€
- **Gemini ë°°ì¹­ í•„ìˆ˜**: 1,500 RPD ë‚´ì—ì„œ ì²˜ë¦¬í•˜ë ¤ë©´ 5-10ê±´ì”© ë°°ì¹˜ í˜¸ì¶œ
- **JSON íŒŒì¼ ì¦ê°€ ë¬¸ì œ**: ë‚ ì§œë³„ ë¶„ë¦¬ ì €ì¥ìœ¼ë¡œ í•´ê²°
- **Git push ë ˆì´ìŠ¤ ì»¨ë””ì…˜**: `concurrency` ê·¸ë£¹ìœ¼ë¡œ ë™ì‹œ ì‹¤í–‰ ë°©ì§€
- **HN API ìˆœì°¨ í˜¸ì¶œ ëŠë¦¼**: `asyncio` + `aiohttp`ë¡œ ë³‘ë ¬ fetch

---

## Work Objectives

### Core Objective
GitHub Actions í¬ë¡  ìŠ¤ì¼€ì¤„ë¡œ ë§¤ì¼ ìë™ ì‹¤í–‰ë˜ëŠ” AI ê¸°ìˆ  ë‰´ìŠ¤ ìˆ˜ì§‘ + ìš”ì•½ + í…”ë ˆê·¸ë¨ ë°œì†¡ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•œë‹¤.

### Concrete Deliverables
- `src/config.py` - ì„¤ì •ê°’ ë° í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬
- `src/scraper.py` - GeekNews Atom í”¼ë“œ + HN API ë°ì´í„° ìˆ˜ì§‘
- `src/ai_handler.py` - Gemini 2.0 Flash ë°°ì¹˜ ìš”ì•½ + ê´€ë ¨ì„± ì ìˆ˜
- `src/storage.py` - JSON ì €ì¥ + ì¤‘ë³µ ë°©ì§€ + GitHub Issues ìƒì„±
- `src/notifier.py` - í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í¬ë§¤íŒ… + ì²­í‚¹ + ë°œì†¡
- `src/main.py` - ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (--dry-run ì§€ì›)
- `.github/workflows/daily-digest.yml` - GitHub Actions ì›Œí¬í”Œë¡œìš°
- `README.md` - ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ + ì„¤ì • ê°€ì´ë“œ + ë¡œì»¬ í…ŒìŠ¤íŠ¸ ë°©ë²•
- `.env.example` - í™˜ê²½ë³€ìˆ˜ í…œí”Œë¦¿
- `requirements.txt` - ì˜ì¡´ì„± ëª©ë¡

### Definition of Done
- [x] `python src/main.py --dry-run` ë¡œì»¬ì—ì„œ ì—ëŸ¬ ì—†ì´ ì‹¤í–‰ë¨
- [x] GeekNews + HNì—ì„œ ê¸°ì‚¬ ìˆ˜ì§‘ë˜ê³  JSONì— ì €ì¥ë¨
- [x] ì¤‘ë³µ ì‹¤í–‰ ì‹œ ë°ì´í„°ê°€ ì¤‘ë³µë˜ì§€ ì•ŠìŒ
- [x] í…”ë ˆê·¸ë¨ìœ¼ë¡œ í¬ë§¤íŒ…ëœ ë‹¤ì´ì œìŠ¤íŠ¸ ë©”ì‹œì§€ ìˆ˜ì‹ ë¨
- [x] GitHub Actions ì›Œí¬í”Œë¡œìš°ê°€ ìœ íš¨í•œ YAMLì„
- [x] GitHub Actionsì—ì„œ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ í…”ë ˆê·¸ë¨ ì•Œë¦¼ ë°œì†¡ë¨

### Must Have
- ë§¤ì¼ ì˜¤ì „ 8ì‹œ KST ìë™ ì‹¤í–‰
- GeekNews + HN ë°ì´í„° ìˆ˜ì§‘
- í‚¤ì›Œë“œ 1ì°¨ í•„í„° + Gemini 2ì°¨ ê´€ë ¨ì„± íŒë‹¨
- 3ì¤„ ìš”ì•½ ìƒì„±
- í…”ë ˆê·¸ë¨ ì¼ì¼ ë‹¤ì´ì œìŠ¤íŠ¸ ë°œì†¡
- JSON ë°ì´í„° ì €ì¥ + Git ìë™ ì»¤ë°‹
- ì£¼ìš” ê¸°ì‚¬ GitHub Issues ìƒì„±
- ì¤‘ë³µ ìˆ˜ì§‘ ë°©ì§€ (seen_ids ê¸°ë°˜)
- ì‹¤íŒ¨ ì‹œ í…”ë ˆê·¸ë¨ ì•Œë¦¼
- --dry-run ëª¨ë“œ (ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
- Gemini ë°°ì¹˜ í˜¸ì¶œ (RPD ì ˆì•½)

### Must NOT Have (Guardrails)
- âŒ í”ŒëŸ¬ê·¸ì¸/ì–´ëŒ‘í„° ì•„í‚¤í…ì²˜ (ì†ŒìŠ¤ í™•ì¥ìš© ì¶”ìƒ ë ˆì´ì–´ ê¸ˆì§€ - GeekNews + HN í•˜ë“œì½”ë”©)
- âŒ YAML/TOML ì„¤ì • íŒŒì¼ íŒŒì„œ (Python ìƒìˆ˜ + .envë§Œ ì‚¬ìš©)
- âŒ ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤ (ë‚´ì¥ ì˜ˆì™¸ + ê°„ë‹¨í•œ try/exceptë§Œ)
- âŒ Pydantic ë˜ëŠ” ë¬´ê±°ìš´ ê²€ì¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ (dataclass ë˜ëŠ” TypedDictê¹Œì§€ë§Œ)
- âŒ ì¬ì‹œë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ (tenacity ë“±) - ê°„ë‹¨í•œ loop ê¸°ë°˜ ì¬ì‹œë„ë§Œ
- âŒ ì›¹ UI, ëŒ€ì‹œë³´ë“œ, ê´€ë¦¬ì íŒ¨ë„
- âŒ SQLite, ORM, ì¶”ìƒ ìŠ¤í† ë¦¬ì§€ ë ˆì´ì–´
- âŒ Reddit, Dev.to ë“± ì¶”ê°€ ì†ŒìŠ¤
- âŒ ì£¼ê°„/ì›”ê°„ ë‹¤ì´ì œìŠ¤íŠ¸ ì§‘ê³„
- âŒ ê¸°ì‚¬ ë³¸ë¬¸ ì „ì²´ ìŠ¤í¬ë˜í•‘
- âŒ ê°ì„± ë¶„ì„, ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜, ë²ˆì—­

---

## Verification Strategy (MANDATORY)

> **UNIVERSAL RULE: ZERO HUMAN INTERVENTION**
>
> ALL tasks in this plan MUST be verifiable WITHOUT any human action.
> ALL verification is executed by the agent using tools (Bash, Playwright, interactive_bash, curl, etc.). No exceptions.

### Test Decision
- **Infrastructure exists**: NO (ìƒˆ í”„ë¡œì íŠ¸)
- **Automated tests**: None (Agent-Executed QAë§Œ)
- **Framework**: None

### Agent-Executed QA Scenarios (MANDATORY â€” ALL tasks)

> QA scenarios are the PRIMARY verification method.
> The executing agent DIRECTLY verifies each deliverable by running it.

**Verification Tool by Deliverable Type:**

| Type | Tool | How Agent Verifies |
|------|------|-------------------|
| Python ëª¨ë“ˆ | Bash (python) | Import, í•¨ìˆ˜ í˜¸ì¶œ, ì¶œë ¥ ê²€ì¦ |
| GitHub Actions YAML | Bash (python yaml.safe_load) | YAML íŒŒì‹± ê²€ì¦ |
| í…”ë ˆê·¸ë¨ ë°œì†¡ | Bash (curl) | Bot API ì§ì ‘ í˜¸ì¶œ í›„ ì‘ë‹µ í™•ì¸ |
| ì „ì²´ íŒŒì´í”„ë¼ì¸ | Bash (python main.py) | --dry-run ì‹¤í–‰ í›„ ì¶œë ¥/íŒŒì¼ ê²€ì¦ |

---

## Execution Strategy

### Parallel Execution Waves

```
Wave 1 (Start Immediately):
â”œâ”€â”€ Task 1: í”„ë¡œì íŠ¸ ì´ˆê¸° ì„¤ì • (config, requirements, .env)
â””â”€â”€ Task 2: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„ë„ (README.md with Mermaid)

Wave 2 (After Wave 1):
â”œâ”€â”€ Task 3: ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ (scraper.py)
â”œâ”€â”€ Task 4: AI ì²˜ë¦¬ ëª¨ë“ˆ (ai_handler.py)
â””â”€â”€ Task 5: ë°ì´í„° ì €ì¥ ëª¨ë“ˆ (storage.py)

Wave 3 (After Wave 2):
â”œâ”€â”€ Task 6: ì•Œë¦¼ ëª¨ë“ˆ (notifier.py)
â””â”€â”€ Task 7: ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (main.py)

Wave 4 (After Wave 3):
â””â”€â”€ Task 8: GitHub Actions ì›Œí¬í”Œë¡œìš° + ìµœì¢… í†µí•© í…ŒìŠ¤íŠ¸

Critical Path: Task 1 â†’ Task 3 â†’ Task 7 â†’ Task 8
Parallel Speedup: ~35% faster than sequential
```

### Dependency Matrix

| Task | Depends On | Blocks | Can Parallelize With |
|------|------------|--------|---------------------|
| 1 | None | 3, 4, 5, 6, 7 | 2 |
| 2 | None | 8 | 1 |
| 3 | 1 | 7 | 4, 5 |
| 4 | 1 | 7 | 3, 5 |
| 5 | 1 | 7 | 3, 4 |
| 6 | 1 | 7 | 3, 4, 5 |
| 7 | 3, 4, 5, 6 | 8 | None |
| 8 | 2, 7 | None | None (final) |

### Agent Dispatch Summary

| Wave | Tasks | Recommended Agents |
|------|-------|-------------------|
| 1 | 1, 2 | task(category="quick") + task(category="writing") |
| 2 | 3, 4, 5 | 3x task(category="unspecified-high") in parallel |
| 3 | 6, 7 | task(category="unspecified-high") sequential (7 depends on 6) |
| 4 | 8 | task(category="deep") for final integration |

---

## TODOs

- [x] 1. í”„ë¡œì íŠ¸ ì´ˆê¸° ì„¤ì • ë° ì„¤ì • ëª¨ë“ˆ

  **What to do**:
  - `requirements.txt` ìƒì„± (ì˜ì¡´ì„± ëª©ë¡):
    ```
    feedparser>=6.0.0
    aiohttp>=3.9.0
    google-generativeai>=0.8.0
    python-dotenv>=1.0.0
    requests>=2.31.0
    ```
  - `.env.example` ìƒì„± (í™˜ê²½ë³€ìˆ˜ í…œí”Œë¦¿):
    ```
    GEMINI_API_KEY=your_gemini_api_key_here
    TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here
    TELEGRAM_CHAT_ID=your_chat_id_here
    DRY_RUN=false
    ```
  - `src/__init__.py` ë¹ˆ íŒŒì¼ ìƒì„±
  - `src/config.py` êµ¬í˜„:
    - `python-dotenv`ë¡œ .env ë¡œë”©
    - ëª¨ë“  ìƒìˆ˜ ì •ì˜ (í‚¤ì›Œë“œ ëª©ë¡, API URL, ë°°ì¹˜ í¬ê¸° ë“±)
    - í‚¤ì›Œë“œ ëª©ë¡: `["AI", "LLM", "GPT", "Gemini", "Claude", "transformer", "deep learning", "machine learning", "React", "TypeScript", "Rust", "Go", "Docker", "Kubernetes", "K8s", "DevOps", "CI/CD", "microservice", "API", "database", "PostgreSQL", "Redis", "cloud", "AWS", "GCP", "Azure", "serverless", "ì¸ê³µì§€ëŠ¥", "ë”¥ëŸ¬ë‹", "ë¨¸ì‹ ëŸ¬ë‹"]`
    - GeekNews Atom URL: `https://news.hada.io/rss/news`
    - HN API base: `https://hacker-news.firebaseio.com/v0/`
    - Gemini model: `gemini-2.0-flash`
    - ë°°ì¹˜ í¬ê¸°: 8 (articles per Gemini call)
    - HN fetch ê°œìˆ˜: 30 (top stories ì¤‘)
    - Gemini ê´€ë ¨ì„± ì ìˆ˜ ì„ê³„ê°’: 0.6 (0~1)
    - Issues ìƒì„± ì ìˆ˜ ì„ê³„ê°’: 0.8
  - `data/` ë””ë ‰í† ë¦¬ì— `.gitkeep` ìƒì„±

  **Must NOT do**:
  - YAML/TOML ì„¤ì • íŒŒì¼ íŒŒì„œ ì‚¬ìš© ê¸ˆì§€
  - Pydantic ì‚¬ìš© ê¸ˆì§€
  - ì„¤ì • í´ë˜ìŠ¤ ìƒì† êµ¬ì¡° ê¸ˆì§€

  **Recommended Agent Profile**:
  - **Category**: `quick`
    - Reason: ë‹¨ìˆœ íŒŒì¼ ìƒì„±ê³¼ ìƒìˆ˜ ì •ì˜. ë³µì¡í•œ ë¡œì§ ì—†ìŒ.
  - **Skills**: []
    - ë³„ë„ ìŠ¤í‚¬ ë¶ˆí•„ìš”
  - **Skills Evaluated but Omitted**:
    - `dev-workflow`: í…ŒìŠ¤íŠ¸ ì—†ìœ¼ë¯€ë¡œ TDD ì›Œí¬í”Œë¡œìš° ë¶ˆí•„ìš”

  **Parallelization**:
  - **Can Run In Parallel**: YES
  - **Parallel Group**: Wave 1 (with Task 2)
  - **Blocks**: Tasks 3, 4, 5, 6, 7
  - **Blocked By**: None (can start immediately)

  **References**:

  **Pattern References**:
  - ì—†ìŒ (ìƒˆ í”„ë¡œì íŠ¸)

  **API/Type References**:
  - ì—†ìŒ

  **External References**:
  - `feedparser` ê³µì‹: https://feedparser.readthedocs.io/
  - `google-generativeai` PyPI: https://pypi.org/project/google-generativeai/
  - `python-dotenv` ê³µì‹: https://github.com/theskumar/python-dotenv
  - Gemini ë¬´ë£Œ í‹°ì–´ ì œí•œ ì°¸ì¡°: gemini-2.0-flash RPM 15, RPD 1,500 (2026.02 ê¸°ì¤€)

  **Acceptance Criteria**:

  **Agent-Executed QA Scenarios:**

  ```
  Scenario: requirements.txtê°€ ìœ íš¨í•˜ê³  ì„¤ì¹˜ ê°€ëŠ¥
    Tool: Bash
    Preconditions: Python 3.11 ì‚¬ìš© ê°€ëŠ¥
    Steps:
      1. pip install -r requirements.txt --dry-run 2>&1
      2. Assert: ì¶œë ¥ì— "ERROR" ì—†ìŒ
      3. Assert: feedparser, aiohttp, google-generativeai, python-dotenv, requests ëª¨ë‘ í¬í•¨
    Expected Result: ëª¨ë“  íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ ê°€ëŠ¥ ìƒíƒœ
    Evidence: ëª…ë ¹ ì¶œë ¥ ìº¡ì²˜

  Scenario: config.pyê°€ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë¨
    Tool: Bash (python)
    Preconditions: .env.example â†’ .envë¡œ ë³µì‚¬ë¨
    Steps:
      1. cp .env.example .env
      2. python -c "from src.config import KEYWORDS, GEEKNEWS_RSS_URL, HN_API_BASE, GEMINI_MODEL, BATCH_SIZE; print(f'Keywords: {len(KEYWORDS)}, URL: {GEEKNEWS_RSS_URL}, HN: {HN_API_BASE}, Model: {GEMINI_MODEL}, Batch: {BATCH_SIZE}')"
      3. Assert: Keywords >= 25
      4. Assert: GEEKNEWS_RSS_URL == "https://news.hada.io/rss/news"
      5. Assert: GEMINI_MODEL == "gemini-2.0-flash"
      6. Assert: BATCH_SIZE == 8
    Expected Result: ëª¨ë“  ì„¤ì •ê°’ì´ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë¨
    Evidence: python ì¶œë ¥ ìº¡ì²˜

  Scenario: .env.exampleì— ëª¨ë“  í•„ìˆ˜ ë³€ìˆ˜ í¬í•¨
    Tool: Bash
    Steps:
      1. grep -c "GEMINI_API_KEY" .env.example
      2. grep -c "TELEGRAM_BOT_TOKEN" .env.example
      3. grep -c "TELEGRAM_CHAT_ID" .env.example
      4. grep -c "DRY_RUN" .env.example
      5. Assert: ëª¨ë‘ 1 ì´ìƒ
    Expected Result: 4ê°œ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ í…œí”Œë¦¿ ì¡´ì¬
    Evidence: grep ì¶œë ¥ ìº¡ì²˜
  ```

  **Commit**: YES
  - Message: `feat(config): add project setup with config module and dependencies`
  - Files: `requirements.txt`, `.env.example`, `src/__init__.py`, `src/config.py`, `data/.gitkeep`
  - Pre-commit: `python -c "from src.config import KEYWORDS; print('OK')"`

---

- [x] 2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„ë„ (README.md)

  **What to do**:
  - `README.md` ì‘ì„±:
    - í”„ë¡œì íŠ¸ ì†Œê°œ (InsightFlow - AI ê¸°ìˆ  íŠ¸ë˜í‚¹)
    - Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ í‘œí˜„:
      ```mermaid
      graph TD
        A[GitHub Actions Cron - 08:00 KST] --> B[scraper.py]
        B --> B1[GeekNews Atom Feed]
        B --> B2[Hacker News API]
        B1 --> C[storage.py - Dedup Check]
        B2 --> C
        C --> D[config.py - Keyword Filter]
        D --> E[ai_handler.py - Gemini Batch]
        E --> F[notifier.py - Telegram]
        E --> G[storage.py - JSON Save]
        G --> H[Git Auto-Commit]
        G --> I[GitHub Issues - Notable Articles]
        F --> J[Daily Digest Message]
      ```
    - ë°ì´í„° íë¦„ ì„¤ëª… (í•œêµ­ì–´)
    - ëª¨ë“ˆë³„ ì—­í•  ì„¤ëª…
    - ë¡œì»¬ ê°œë°œ í™˜ê²½ ì„¤ì • ê°€ì´ë“œ:
      1. ë ˆí¬ í´ë¡ 
      2. Python 3.11 + venv ìƒì„±
      3. `pip install -r requirements.txt`
      4. `.env.example` â†’ `.env` ë³µì‚¬ í›„ ì‹¤ì œ í‚¤ ì…ë ¥
      5. `python src/main.py --dry-run` ì‹¤í–‰
    - GitHub Actions ì„¤ì • ê°€ì´ë“œ:
      1. GitHub Secrets ì„¤ì • (GEMINI_API_KEY, TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID)
      2. Actions íƒ­ì—ì„œ ì›Œí¬í”Œë¡œìš° í™œì„±í™”
      3. ìˆ˜ë™ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (workflow_dispatch)
    - í…”ë ˆê·¸ë¨ ë´‡ ì„¤ì • ë°©ë²•:
      1. @BotFatherë¡œ ë´‡ ìƒì„±
      2. ë´‡ í† í° íšë“
      3. chat_id í™•ì¸ ë°©ë²•
    - Gemini API í‚¤ ë°œê¸‰ ë°©ë²• (Google AI Studio)
    - ì‹¤íŒ¨ ì‹œ ì•Œë¦¼ ë™ì‘ ì„¤ëª…
    - ì¤‘ë³µ ë°©ì§€ ë©”ì»¤ë‹ˆì¦˜ ì„¤ëª…

  **Must NOT do**:
  - ì˜ì–´ë¡œ ì‘ì„± ê¸ˆì§€ (í•œêµ­ì–´ í”„ë¡œì íŠ¸)
  - ê³¼ë„í•œ ë±ƒì§€/ì´ë¯¸ì§€ ì¶”ê°€ ê¸ˆì§€
  - ê¸°ì—¬ ê°€ì´ë“œ/CoC ì¶”ê°€ ê¸ˆì§€ (ê°œì¸ í”„ë¡œì íŠ¸)

  **Recommended Agent Profile**:
  - **Category**: `writing`
    - Reason: ë¬¸ì„œ ì‘ì„± ì¤‘ì‹¬ ì‘ì—…. Mermaid ë‹¤ì´ì–´ê·¸ë¨ + ê°€ì´ë“œ ì‘ì„±.
  - **Skills**: [`doc-writer`]
    - `doc-writer`: ë¬¸ì„œ êµ¬ì¡°í™”ì™€ ëª…í™•í•œ ê¸°ìˆ  ë¬¸ì„œ ì‘ì„±ì— íŠ¹í™”
  - **Skills Evaluated but Omitted**:
    - `frontend-ui-ux`: ë¬¸ì„œ ì‘ì„±ì´ë¯€ë¡œ UI ìŠ¤í‚¬ ë¶ˆí•„ìš”

  **Parallelization**:
  - **Can Run In Parallel**: YES
  - **Parallel Group**: Wave 1 (with Task 1)
  - **Blocks**: Task 8
  - **Blocked By**: None (can start immediately)

  **References**:

  **Pattern References**:
  - `aastroza/rss-feeds-scraper` (https://github.com/aastroza/rss-feeds-scraper) - GitHub Actions + RSS + JSON ìë™ì»¤ë°‹ í”„ë¡œì íŠ¸ êµ¬ì¡° ì°¸ê³ 

  **Documentation References**:
  - Mermaid ê³µì‹ ë¬¸ë²•: https://mermaid.js.org/syntax/flowchart.html
  - GitHub Actions ìŠ¤ì¼€ì¤„ íŠ¸ë¦¬ê±°: https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#schedule
  - Telegram BotFather: https://core.telegram.org/bots#botfather
  - Google AI Studio: https://aistudio.google.com/

  **WHY Each Reference Matters**:
  - aastroza í”„ë¡œì íŠ¸: ìœ ì‚¬í•œ ì•„í‚¤í…ì²˜ë¡œ ì‹¤ì œ ìš´ì˜ ì¤‘ì¸ í”„ë¡œì íŠ¸. README êµ¬ì¡° ì°¸ê³ .
  - Mermaid: ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ì‘ì„±ì— í•„ìš”í•œ ë¬¸ë²•

  **Acceptance Criteria**:

  **Agent-Executed QA Scenarios:**

  ```
  Scenario: README.mdê°€ ìœ íš¨í•˜ê³  í•µì‹¬ ì„¹ì…˜ í¬í•¨
    Tool: Bash
    Steps:
      1. test -f README.md && echo "EXISTS"
      2. Assert: "EXISTS" ì¶œë ¥
      3. grep -c "mermaid" README.md
      4. Assert: >= 1 (Mermaid ë‹¤ì´ì–´ê·¸ë¨ í¬í•¨)
      5. grep -c "ë¡œì»¬" README.md
      6. Assert: >= 1 (ë¡œì»¬ ê°œë°œ ê°€ì´ë“œ í¬í•¨)
      7. grep -c "GitHub Actions" README.md
      8. Assert: >= 1
      9. grep -c "í…”ë ˆê·¸ë¨" README.md
      10. Assert: >= 1
    Expected Result: READMEì— ì•„í‚¤í…ì²˜, ë¡œì»¬ ê°€ì´ë“œ, Actions, í…”ë ˆê·¸ë¨ ì„¹ì…˜ ì¡´ì¬
    Evidence: grep ì¶œë ¥ ìº¡ì²˜
  ```

  **Commit**: YES
  - Message: `docs: add README with architecture diagram and setup guide`
  - Files: `README.md`
  - Pre-commit: `test -f README.md`

---

- [x] 3. ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ (scraper.py)

  **What to do**:
  - `src/scraper.py` êµ¬í˜„:
    - `@dataclass Article` ì •ì˜:
      - `source: str` ("geeknews" | "hackernews")
      - `source_id: str` (GeekNews topic ID | HN item ID)
      - `title: str`
      - `url: str` (ì›ë³¸ ê¸°ì‚¬ URL)
      - `discussion_url: str` (GeekNews/HN í† ë¡  í˜ì´ì§€ URL)
      - `summary: str` (GeekNews ê¸°ì¡´ ìš”ì•½ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´)
      - `score: int` (HN ì ìˆ˜ ë˜ëŠ” 0)
      - `published_at: str` (ISO 8601)
      - `ai_summary: str = ""` (Geminiê°€ ì±„ìš¸ í•„ë“œ)
      - `relevance_score: float = 0.0` (Geminiê°€ ì±„ìš¸ í•„ë“œ)

    - `fetch_geeknews() -> list[Article]`:
      - `feedparser.parse("https://news.hada.io/rss/news")` í˜¸ì¶œ
      - **ì¤‘ìš”**: User-Agent í—¤ë” ì„¤ì • (GitHub Actionsì—ì„œ 403 ë°©ì§€)
      - Atom í”¼ë“œ íŒŒì‹±: `entry.title`, `entry.link` (í† ë¡  í˜ì´ì§€), `entry.id`, `entry.content[0].value` (í•œêµ­ì–´ ìš”ì•½)
      - **ì›ë³¸ URL ì¶”ì¶œ**: GeekNews Atom í”¼ë“œì—ëŠ” ì›ë³¸ URLì´ ì—†ìŒ. ê° í† í”½ í˜ì´ì§€(`https://news.hada.io/topic?id=XXXXX`)ë¥¼ requestsë¡œ fetchí•˜ì—¬ ì›ë³¸ URLì„ íŒŒì‹±í•˜ê±°ë‚˜, `entry.link`ì„ discussion_urlë¡œ ì‚¬ìš©í•˜ê³  `entry.content`ì˜ ì²« ë²ˆì§¸ ë§í¬ë¥¼ ì›ë³¸ URLë¡œ ì¶”ì¶œ
      - ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ + ì—ëŸ¬ ë¡œê¹…
      - `<published>` ë‚ ì§œë¡œ ìµœê·¼ 24ì‹œê°„ ê¸°ì‚¬ë§Œ í•„í„°ë§

    - `fetch_hackernews(count: int = 30) -> list[Article]`:
      - `aiohttp` ì‚¬ìš©í•œ ë¹„ë™ê¸° fetch
      - Step 1: `/v0/topstories.json` â†’ ìƒìœ„ `count`ê°œ ID ì¶”ì¶œ
      - Step 2: `asyncio.gather()`ë¡œ `/v0/item/{id}.json` ë³‘ë ¬ fetch (30ê°œ ë™ì‹œ)
      - ê° ì•„ì´í…œì—ì„œ `title`, `url` (ì—†ìœ¼ë©´ self-post), `score`, `time` ì¶”ì¶œ
      - `discussion_url`: `https://news.ycombinator.com/item?id={id}`
      - self-post (url ì—†ìŒ)ëŠ” `discussion_url`ì„ `url`ë¡œ ì‚¬ìš©
      - ì‹¤íŒ¨í•œ ê°œë³„ ì•„ì´í…œì€ skip + ì—ëŸ¬ ë¡œê¹…
      - ì „ì²´ fetch ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

    - `scrape_all() -> list[Article]`:
      - `fetch_geeknews()` + `fetch_hackernews()` í˜¸ì¶œ
      - ë‘ ê²°ê³¼ í•©ì³ì„œ ë°˜í™˜
      - ê° ì†ŒìŠ¤ ì‹¤íŒ¨ëŠ” ë…ë¦½ì  (í•˜ë‚˜ ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ ì†ŒìŠ¤ ê²°ê³¼ëŠ” ë°˜í™˜)

  **Must NOT do**:
  - ì¶”ìƒ Source í´ë˜ìŠ¤/ì¸í„°í˜ì´ìŠ¤ ìƒì„± ê¸ˆì§€
  - ë‹¤ë¥¸ ì†ŒìŠ¤ ì§€ì› ì½”ë“œ ê¸ˆì§€
  - ê¸°ì‚¬ ë³¸ë¬¸ ì „ì²´ ìŠ¤í¬ë˜í•‘ ê¸ˆì§€
  - BeautifulSoup ê³¼ë„í•œ ì‚¬ìš© ê¸ˆì§€ (í”¼ë“œ íŒŒì‹±ì€ feedparserë¡œ)

  **Recommended Agent Profile**:
  - **Category**: `unspecified-high`
    - Reason: Atom í”¼ë“œ íŒŒì‹± + ë¹„ë™ê¸° HTTP + ì›ë³¸ URL ì¶”ì¶œ ë“± ì¤‘ê°„ ë³µì¡ë„. ì—¬ëŸ¬ ì™¸ë¶€ APIì™€ ìƒí˜¸ì‘ìš©.
  - **Skills**: []
    - ë³„ë„ ìŠ¤í‚¬ ë¶ˆí•„ìš” (í‘œì¤€ Python ì‘ì—…)
  - **Skills Evaluated but Omitted**:
    - `dev-workflow`: í…ŒìŠ¤íŠ¸ ì—†ìœ¼ë¯€ë¡œ ë¶ˆí•„ìš”

  **Parallelization**:
  - **Can Run In Parallel**: YES
  - **Parallel Group**: Wave 2 (with Tasks 4, 5)
  - **Blocks**: Task 7
  - **Blocked By**: Task 1

  **References**:

  **Pattern References**:
  - `src/config.py` (Task 1ì—ì„œ ìƒì„±) - `GEEKNEWS_RSS_URL`, `HN_API_BASE`, `HN_TOP_N` ìƒìˆ˜ ì‚¬ìš©

  **API/Type References**:
  - GeekNews Atom Feed: `https://news.hada.io/rss/news` - Atom í˜•ì‹ (`xmlns='http://www.w3.org/2005/Atom'`)
    - `<entry>` í•˜ìœ„: `<title>` (CDATA Korean), `<link rel='alternate' href='...'>` (í† ë¡  í˜ì´ì§€), `<id>`, `<published>` (ISO 8601 +09:00), `<content type='html'>` (í•œêµ­ì–´ ìš”ì•½)
    - **ì£¼ì˜**: `<link>`ëŠ” ì›ë³¸ URLì´ ì•„ë‹Œ GeekNews í† ë¡  í˜ì´ì§€ URL
  - HN API: `https://hacker-news.firebaseio.com/v0/`
    - `/topstories.json` â†’ `int[]` (ìµœëŒ€ 500ê°œ)
    - `/item/{id}.json` â†’ `{id, by, title, url?, score, time, descendants, type}`
    - `url`ì´ ì—†ìœ¼ë©´ self-post (Ask HN, Show HN ë“±)

  **External References**:
  - feedparser ê³µì‹ ë¬¸ì„œ: https://feedparser.readthedocs.io/en/latest/
    - Atom í”¼ë“œë„ RSSì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ íŒŒì‹± (`feed.entries`, `entry.title`, `entry.link`)
  - aiohttp ê³µì‹: https://docs.aiohttp.org/en/stable/
  - HN API ê³µì‹: https://github.com/HackerNews/API

  **WHY Each Reference Matters**:
  - GeekNews Atom êµ¬ì¡°ë¥¼ ì •í™•íˆ ì•Œì•„ì•¼ ì˜¬ë°”ë¥¸ í•„ë“œë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆìŒ (íŠ¹íˆ ì›ë³¸ URL ëˆ„ë½ ë¬¸ì œ)
  - HN APIëŠ” ë°°ì¹˜ ë¯¸ì§€ì›ì´ë¯€ë¡œ aiohttp ë¹„ë™ê¸° íŒ¨í„´ì´ í•„ìˆ˜
  - feedparserëŠ” Atom/RSS ëª¨ë‘ ì²˜ë¦¬í•˜ë¯€ë¡œ í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš© ê°€ëŠ¥

  **Acceptance Criteria**:

  **Agent-Executed QA Scenarios:**

  ```
  Scenario: GeekNews Atom í”¼ë“œ ìˆ˜ì§‘ ì„±ê³µ
    Tool: Bash (python)
    Preconditions: requirements.txt ì„¤ì¹˜ë¨, ì¸í„°ë„· ì—°ê²°ë¨
    Steps:
      1. pip install -r requirements.txt
      2. python -c "
         from src.scraper import fetch_geeknews
         articles = fetch_geeknews()
         print(f'Count: {len(articles)}')
         if articles:
             a = articles[0]
             print(f'Title: {a.title[:50]}')
             print(f'Source: {a.source}')
             print(f'URL: {a.url}')
             print(f'Discussion: {a.discussion_url}')
             print(f'Has summary: {bool(a.summary)}')
         "
      3. Assert: Count > 0
      4. Assert: Source == "geeknews"
      5. Assert: URLì€ ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹˜ (ì›ë³¸ URL ë˜ëŠ” í† ë¡  URL)
      6. Assert: Discussion URLì— "news.hada.io" í¬í•¨
    Expected Result: GeekNewsì—ì„œ ìµœì†Œ 1ê°œ ì´ìƒì˜ ê¸°ì‚¬ ìˆ˜ì§‘
    Evidence: python ì¶œë ¥ ìº¡ì²˜

  Scenario: Hacker News API ìˆ˜ì§‘ ì„±ê³µ
    Tool: Bash (python)
    Preconditions: requirements.txt ì„¤ì¹˜ë¨, ì¸í„°ë„· ì—°ê²°ë¨
    Steps:
      1. python -c "
         import asyncio
         from src.scraper import fetch_hackernews
         articles = asyncio.run(fetch_hackernews(count=5))
         print(f'Count: {len(articles)}')
         if articles:
             a = articles[0]
             print(f'Title: {a.title[:50]}')
             print(f'Source: {a.source}')
             print(f'Score: {a.score}')
             print(f'URL: {a.url}')
         "
      2. Assert: Count >= 3 (5ê°œ ì¤‘ ìµœì†Œ 3ê°œëŠ” ì„±ê³µí•´ì•¼ í•¨)
      3. Assert: Source == "hackernews"
      4. Assert: Score > 0
    Expected Result: HNì—ì„œ ìµœì†Œ 3ê°œ ì´ìƒì˜ ê¸°ì‚¬ ìˆ˜ì§‘
    Evidence: python ì¶œë ¥ ìº¡ì²˜

  Scenario: scrape_allì´ ë‘ ì†ŒìŠ¤ë¥¼ í•©ì³ì„œ ë°˜í™˜
    Tool: Bash (python)
    Steps:
      1. python -c "
         from src.scraper import scrape_all
         articles = scrape_all()
         sources = set(a.source for a in articles)
         print(f'Total: {len(articles)}')
         print(f'Sources: {sources}')
         "
      2. Assert: Total > 0
      3. Assert: sourcesì— "geeknews" ë˜ëŠ” "hackernews" ì¤‘ ìµœì†Œ 1ê°œ í¬í•¨
    Expected Result: ë‘ ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘ëœ ê¸°ì‚¬ ëª©ë¡ ë°˜í™˜
    Evidence: python ì¶œë ¥ ìº¡ì²˜

  Scenario: ë„¤íŠ¸ì›Œí¬ ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (graceful degradation)
    Tool: Bash (python)
    Steps:
      1. python -c "
         import feedparser
         # ì˜ëª»ëœ URLë¡œ í…ŒìŠ¤íŠ¸
         result = feedparser.parse('https://invalid-url-that-does-not-exist.example.com/rss')
         print(f'Entries: {len(result.entries)}')
         print(f'Bozo: {result.bozo}')
         "
      2. Assert: Entries == 0
      3. Assert: ì—ëŸ¬ ì—†ì´ ì‹¤í–‰ ì™„ë£Œë¨ (exit code 0)
    Expected Result: ì˜ëª»ëœ URLì—ë„ í¬ë˜ì‹œ ì—†ì´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
    Evidence: python ì¶œë ¥ ìº¡ì²˜
  ```

  **Commit**: YES
  - Message: `feat(scraper): add GeekNews Atom feed and HN API data collection`
  - Files: `src/scraper.py`
  - Pre-commit: `python -c "from src.scraper import scrape_all; print('OK')"`

---

- [x] 4. AI ì²˜ë¦¬ ëª¨ë“ˆ (ai_handler.py)

  **What to do**:
  - `src/ai_handler.py` êµ¬í˜„:
    - `keyword_filter(articles: list[Article]) -> list[Article]`:
      - `config.KEYWORDS` ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ 1ì°¨ í•„í„°ë§
      - ê° ê¸°ì‚¬ì˜ `title` + `summary`ì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
      - ë§¤ì¹­ëœ ê¸°ì‚¬ë§Œ ë°˜í™˜ (Gemini API í˜¸ì¶œ ìµœì†Œí™”)
      - í•œêµ­ì–´ í‚¤ì›Œë“œë„ í¬í•¨ (`ì¸ê³µì§€ëŠ¥`, `ë”¥ëŸ¬ë‹` ë“±)

    - `batch_summarize(articles: list[Article]) -> list[Article]`:
      - `google.generativeai` SDK ì‚¬ìš©
      - `GEMINI_API_KEY`ë¡œ ì¸ì¦
      - ê¸°ì‚¬ë¥¼ `config.BATCH_SIZE` (8ê°œ)ì”© ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ”
      - ê° ë°°ì¹˜ì— ëŒ€í•´ Gemini í˜¸ì¶œ:
        - **í”„ë¡¬í”„íŠ¸ ì„¤ê³„**:
          ```
          ë‹¤ìŒ ê¸°ìˆ  ê¸°ì‚¬ë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. ê° ê¸°ì‚¬ì— ëŒ€í•´:
          1. ê°œë°œì ê´€ë ¨ì„± ì ìˆ˜ (0.0~1.0)
          2. í•œêµ­ì–´ë¡œ 3ì¤„ í•µì‹¬ ìš”ì•½

          ê¸°ì‚¬ ëª©ë¡:
          [1] ì œëª©: {title}
              ìš”ì•½: {summary}
          [2] ...

          JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
          [{"index": 1, "relevance": 0.85, "summary": "..."}, ...]
          ```
        - JSON ì‘ë‹µ íŒŒì‹±í•˜ì—¬ ê° Articleì˜ `ai_summary`, `relevance_score` ì—…ë°ì´íŠ¸
      - Rate limit ëŒ€ì‘: ë°°ì¹˜ ê°„ 2ì´ˆ ëŒ€ê¸° (`time.sleep(2)`)
      - 429 ì—ëŸ¬ ì‹œ 3íšŒ ì¬ì‹œë„ (ì§€ìˆ˜ ë°±ì˜¤í”„: 5s, 15s, 45s)
      - ì „ì²´ Gemini ì‹¤íŒ¨ ì‹œ graceful degradation: í‚¤ì›Œë“œ í•„í„° ê²°ê³¼ë§Œ ë°˜í™˜ (AI ìš”ì•½ ì—†ì´)

    - `filter_and_summarize(articles: list[Article]) -> list[Article]`:
      - Step 1: `keyword_filter(articles)` â†’ í‚¤ì›Œë“œ ë§¤ì¹­ëœ ê¸°ì‚¬
      - Step 2: `batch_summarize(filtered)` â†’ AI ìš”ì•½ + ê´€ë ¨ì„± ì ìˆ˜ ì¶”ê°€
      - Step 3: `relevance_score >= config.RELEVANCE_THRESHOLD` (0.6) ì´ìƒë§Œ ìµœì¢… ë°˜í™˜
      - `relevance_score >= config.ISSUE_THRESHOLD` (0.8) ê¸°ì‚¬ì— `notable` í”Œë˜ê·¸

  **Must NOT do**:
  - Pydantic ëª¨ë¸ ì‚¬ìš© ê¸ˆì§€
  - tenacity ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¸ˆì§€ (ê°„ë‹¨í•œ ë£¨í”„ ì¬ì‹œë„ë§Œ)
  - ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤ ìƒì„± ê¸ˆì§€
  - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì—”ì§„ ì‚¬ìš© ê¸ˆì§€ (f-stringë§Œ)
  - ê°ì„± ë¶„ì„, ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ë“± ì¶”ê°€ AI ê¸°ëŠ¥ ê¸ˆì§€

  **Recommended Agent Profile**:
  - **Category**: `unspecified-high`
    - Reason: Gemini API í†µí•©, ë°°ì¹˜ ì²˜ë¦¬ ë¡œì§, ì—ëŸ¬ í•¸ë“¤ë§, JSON íŒŒì‹± ë“± ì¤‘ê°„-ë†’ì€ ë³µì¡ë„
  - **Skills**: []
  - **Skills Evaluated but Omitted**:
    - `ultrabrain`: API í†µí•©ì€ ë³µì¡í•˜ì§€ë§Œ ë¡œì§ ìì²´ëŠ” ì§ê´€ì 

  **Parallelization**:
  - **Can Run In Parallel**: YES
  - **Parallel Group**: Wave 2 (with Tasks 3, 5)
  - **Blocks**: Task 7
  - **Blocked By**: Task 1

  **References**:

  **Pattern References**:
  - `src/config.py` (Task 1) - KEYWORDS, GEMINI_API_KEY, GEMINI_MODEL, BATCH_SIZE, RELEVANCE_THRESHOLD
  - `src/scraper.py:Article` (Task 3) - Article dataclass êµ¬ì¡°

  **API/Type References**:
  - Gemini Python SDK: `google.generativeai`
    - `genai.configure(api_key=...)` â†’ ì´ˆê¸°í™”
    - `model = genai.GenerativeModel('gemini-2.0-flash')` â†’ ëª¨ë¸ ìƒì„±
    - `response = model.generate_content(prompt)` â†’ ì‘ë‹µ ìƒì„±
    - `response.text` â†’ í…ìŠ¤íŠ¸ ì‘ë‹µ
  - ë¬´ë£Œ í‹°ì–´ ì œí•œ: RPM 15, RPD 1,500 (2026.02 ê¸°ì¤€)
  - JSON ì‘ë‹µ ëª¨ë“œ: `generation_config=genai.GenerationConfig(response_mime_type="application/json")`

  **External References**:
  - google-generativeai í€µìŠ¤íƒ€íŠ¸: https://ai.google.dev/gemini-api/docs/quickstart
  - Gemini ë¬´ë£Œ í‹°ì–´ ì œí•œ: https://ai.google.dev/gemini-api/docs/rate-limits

  **WHY Each Reference Matters**:
  - Gemini SDK ì‚¬ìš©ë²•ì„ ì •í™•íˆ ì•Œì•„ì•¼ ì˜¬ë°”ë¥¸ API í˜¸ì¶œ ê°€ëŠ¥
  - ë¬´ë£Œ í‹°ì–´ ì œí•œì„ ì´í•´í•´ì•¼ ë°°ì¹˜ í¬ê¸°ì™€ ëŒ€ê¸° ì‹œê°„ ìµœì í™” ê°€ëŠ¥
  - JSON ì‘ë‹µ ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ë©´ ì‘ë‹µ íŒŒì‹±ì´ ì•ˆì •ì 

  **Acceptance Criteria**:

  **Agent-Executed QA Scenarios:**

  ```
  Scenario: í‚¤ì›Œë“œ í•„í„°ë§ì´ ì˜¬ë°”ë¥´ê²Œ ë™ì‘
    Tool: Bash (python)
    Preconditions: src/scraper.pyì˜ Article dataclass ì‚¬ìš© ê°€ëŠ¥
    Steps:
      1. python -c "
         from src.scraper import Article
         from src.ai_handler import keyword_filter
         articles = [
             Article(source='test', source_id='1', title='New AI Model Released', url='http://a.com', discussion_url='', summary='', score=0, published_at=''),
             Article(source='test', source_id='2', title='Cooking Recipe Today', url='http://b.com', discussion_url='', summary='', score=0, published_at=''),
             Article(source='test', source_id='3', title='Docker Container Best Practices', url='http://c.com', discussion_url='', summary='', score=0, published_at=''),
         ]
         filtered = keyword_filter(articles)
         print(f'Input: {len(articles)}, Filtered: {len(filtered)}')
         titles = [a.title for a in filtered]
         print(f'Titles: {titles}')
         "
      2. Assert: Filtered == 2 (AI + Docker ê¸°ì‚¬ë§Œ)
      3. Assert: "Cooking Recipe" ê¸°ì‚¬ê°€ í•„í„°ë§ë¨
    Expected Result: í‚¤ì›Œë“œ í¬í•¨ ê¸°ì‚¬ë§Œ í†µê³¼
    Evidence: python ì¶œë ¥ ìº¡ì²˜

  Scenario: Gemini ë°°ì¹˜ ìš”ì•½ ì„±ê³µ (ì‹¤ì œ API í˜¸ì¶œ)
    Tool: Bash (python)
    Preconditions: .envì— ìœ íš¨í•œ GEMINI_API_KEY ì„¤ì •ë¨
    Steps:
      1. python -c "
         from src.scraper import Article
         from src.ai_handler import batch_summarize
         articles = [
             Article(source='test', source_id='1', title='OpenAI Releases GPT-5', url='http://a.com', discussion_url='', summary='OpenAI released GPT-5 with improved reasoning capabilities', score=100, published_at='2026-02-10'),
         ]
         result = batch_summarize(articles)
         if result:
             a = result[0]
             print(f'AI Summary: {a.ai_summary[:100]}')
             print(f'Relevance: {a.relevance_score}')
             print(f'Has summary: {bool(a.ai_summary)}')
         else:
             print('EMPTY - Gemini may have failed')
         "
      2. Assert: Has summary == True
      3. Assert: 0.0 <= Relevance <= 1.0
    Expected Result: Geminiê°€ ìš”ì•½ê³¼ ê´€ë ¨ì„± ì ìˆ˜ ë°˜í™˜
    Evidence: python ì¶œë ¥ ìº¡ì²˜

  Scenario: Gemini ì‹¤íŒ¨ ì‹œ graceful degradation
    Tool: Bash (python)
    Preconditions: ì˜ëª»ëœ API í‚¤ ì‚¬ìš©
    Steps:
      1. GEMINI_API_KEY=invalid_key python -c "
         from src.scraper import Article
         from src.ai_handler import filter_and_summarize
         articles = [
             Article(source='test', source_id='1', title='AI Model Test', url='http://a.com', discussion_url='', summary='Test summary', score=0, published_at=''),
         ]
         result = filter_and_summarize(articles)
         print(f'Count: {len(result)}')
         print(f'Has AI summary: {bool(result[0].ai_summary) if result else False}')
         " 2>&1
      2. Assert: í”„ë¡œê·¸ë¨ì´ í¬ë˜ì‹œí•˜ì§€ ì•ŠìŒ (exit code 0)
      3. Assert: Count >= 0 (ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” AI ìš”ì•½ ì—†ëŠ” ê¸°ì‚¬ ë°˜í™˜)
    Expected Result: Gemini ì‹¤íŒ¨í•´ë„ í¬ë˜ì‹œ ì—†ì´ í‚¤ì›Œë“œ í•„í„° ê²°ê³¼ ë°˜í™˜
    Evidence: python ì¶œë ¥ ìº¡ì²˜
  ```

  **Commit**: YES
  - Message: `feat(ai): add Gemini batch summarization with keyword filtering`
  - Files: `src/ai_handler.py`
  - Pre-commit: `python -c "from src.ai_handler import filter_and_summarize; print('OK')"`

---

- [x] 5. ë°ì´í„° ì €ì¥ ëª¨ë“ˆ (storage.py)

  **What to do**:
  - `src/storage.py` êµ¬í˜„:
    - `load_seen_ids() -> set[str]`:
      - `data/seen_ids.json` íŒŒì¼ì—ì„œ ì´ì „ì— ì²˜ë¦¬ëœ ê¸°ì‚¬ ID ì„¸íŠ¸ ë¡œë“œ
      - íŒŒì¼ ì—†ìœ¼ë©´ ë¹ˆ set ë°˜í™˜
      - í‚¤ í˜•ì‹: `"{source}:{source_id}"` (ì˜ˆ: `"geeknews:12345"`, `"hackernews:67890"`)

    - `save_seen_ids(seen_ids: set[str])`:
      - `data/seen_ids.json`ì— JSON ë°°ì—´ë¡œ ì €ì¥
      - ì •ë ¬í•˜ì—¬ ì €ì¥ (git diff ìµœì†Œí™”)

    - `filter_new_articles(articles: list[Article], seen_ids: set[str]) -> list[Article]`:
      - ê° ê¸°ì‚¬ì˜ `"{source}:{source_id}"`ê°€ seen_idsì— ì—†ëŠ” ê²ƒë§Œ ë°˜í™˜
      - ìƒˆ ê¸°ì‚¬ì˜ IDë¥¼ seen_idsì— ì¶”ê°€

    - `save_daily_articles(articles: list[Article], date_str: str)`:
      - `data/{YYYY}/{MM}/{DD}.json` ê²½ë¡œì— ì €ì¥
      - ë””ë ‰í† ë¦¬ ìë™ ìƒì„± (`os.makedirs(exist_ok=True)`)
      - ê¸°ì‚¬ë¥¼ dict ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ JSON ì €ì¥ (indent=2, ensure_ascii=False)
      - ì´ë¯¸ íŒŒì¼ ì¡´ì¬ ì‹œ ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€ (append)

    - `create_github_issues(articles: list[Article])`:
      - `relevance_score >= config.ISSUE_THRESHOLD` (0.8) ì´ìƒì¸ ê¸°ì‚¬ë§Œ
      - GitHub API (`GITHUB_TOKEN` í™˜ê²½ë³€ìˆ˜) ì‚¬ìš©
      - Issue ì œëª©: `[{source}] {title}`
      - Issue ë³¸ë¬¸:
        ```
        ## ê¸°ì‚¬ ì •ë³´
        - **ì›ë³¸ URL**: {url}
        - **í† ë¡ **: {discussion_url}
        - **ì†ŒìŠ¤**: {source}
        - **ê´€ë ¨ì„± ì ìˆ˜**: {relevance_score}

        ## AI ìš”ì•½
        {ai_summary}
        ```
      - ë¼ë²¨: `source:{source}`, `auto-collected`
      - í•˜ë£¨ ìµœëŒ€ 5ê°œ Issue ìƒì„± (GitHub API ë¶€í•˜ ë°©ì§€)
      - dry-run ëª¨ë“œì—ì„œëŠ” ìŠ¤í‚µ

  **Must NOT do**:
  - SQLite, ORM ì‚¬ìš© ê¸ˆì§€
  - ì¶”ìƒ ìŠ¤í† ë¦¬ì§€ ë ˆì´ì–´ ê¸ˆì§€
  - ì „ì²´ ì´ë ¥ì„ ë‹¨ì¼ íŒŒì¼ì— ì €ì¥ ê¸ˆì§€ (ë‚ ì§œë³„ ë¶„ë¦¬ í•„ìˆ˜)
  - ë³µì¡í•œ ì¸ë±ì‹±/ê²€ìƒ‰ ë¡œì§ ê¸ˆì§€

  **Recommended Agent Profile**:
  - **Category**: `unspecified-high`
    - Reason: íŒŒì¼ I/O, JSON ì²˜ë¦¬, GitHub API í†µí•©, ì¤‘ë³µ ë°©ì§€ ë¡œì§
  - **Skills**: []
  - **Skills Evaluated but Omitted**:
    - `git-master`: git ì‘ì—…ì€ GitHub Actionsì—ì„œ ìˆ˜í–‰í•˜ë¯€ë¡œ ì§ì ‘ì  ê´€ë ¨ ì—†ìŒ

  **Parallelization**:
  - **Can Run In Parallel**: YES
  - **Parallel Group**: Wave 2 (with Tasks 3, 4)
  - **Blocks**: Task 7
  - **Blocked By**: Task 1

  **References**:

  **Pattern References**:
  - `src/config.py` (Task 1) - ISSUE_THRESHOLD, data ë””ë ‰í† ë¦¬ ê²½ë¡œ
  - `src/scraper.py:Article` (Task 3) - Article dataclass êµ¬ì¡°

  **API/Type References**:
  - GitHub REST API - Issues: `POST /repos/{owner}/{repo}/issues`
    - Headers: `Authorization: Bearer {GITHUB_TOKEN}`, `Accept: application/vnd.github.v3+json`
    - Body: `{"title": "...", "body": "...", "labels": [...]}`
  - `GITHUB_TOKEN`: GitHub Actionsì—ì„œ ìë™ ì œê³µ (`${{ secrets.GITHUB_TOKEN }}`)
  - `GITHUB_REPOSITORY`: í™˜ê²½ë³€ìˆ˜ë¡œ `owner/repo` í˜•ì‹ ìë™ ì œê³µ

  **External References**:
  - GitHub REST API Issues: https://docs.github.com/en/rest/issues/issues#create-an-issue

  **WHY Each Reference Matters**:
  - GitHub Issues APIë¥¼ ì˜¬ë°”ë¥´ê²Œ í˜¸ì¶œí•˜ë ¤ë©´ ì¸ì¦ ë°©ì‹ê³¼ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì •í™•íˆ ì•Œì•„ì•¼ í•¨
  - `GITHUB_TOKEN`ê³¼ `GITHUB_REPOSITORY` í™˜ê²½ë³€ìˆ˜ëŠ” Actionsì—ì„œ ìë™ ì œê³µë¨ì„ ì•Œì•„ì•¼ í•¨

  **Acceptance Criteria**:

  **Agent-Executed QA Scenarios:**

  ```
  Scenario: ì¤‘ë³µ ë°©ì§€ (seen_ids) ë™ì‘ í™•ì¸
    Tool: Bash (python)
    Preconditions: data/ ë””ë ‰í† ë¦¬ ì¡´ì¬
    Steps:
      1. python -c "
         from src.storage import load_seen_ids, save_seen_ids, filter_new_articles
         from src.scraper import Article
         # ì´ˆê¸° ìƒíƒœ: ë¹ˆ seen_ids
         seen = load_seen_ids()
         print(f'Initial seen: {len(seen)}')
         
         articles = [
             Article(source='test', source_id='1', title='A', url='', discussion_url='', summary='', score=0, published_at=''),
             Article(source='test', source_id='2', title='B', url='', discussion_url='', summary='', score=0, published_at=''),
         ]
         new = filter_new_articles(articles, seen)
         print(f'First run new: {len(new)}')
         save_seen_ids(seen)
         
         # ë™ì¼ ê¸°ì‚¬ë¡œ ì¬ì‹¤í–‰
         seen2 = load_seen_ids()
         new2 = filter_new_articles(articles, seen2)
         print(f'Second run new: {len(new2)}')
         "
      2. Assert: Initial seen == 0
      3. Assert: First run new == 2
      4. Assert: Second run new == 0 (ì¤‘ë³µ ì œê±°ë¨)
    Expected Result: ê°™ì€ ê¸°ì‚¬ë¥¼ ë‘ ë²ˆ ì²˜ë¦¬í•˜ë©´ ë‘ ë²ˆì§¸ì—ëŠ” ìƒˆ ê¸°ì‚¬ê°€ 0ê°œ
    Evidence: python ì¶œë ¥ ìº¡ì²˜

  Scenario: ì¼ì¼ ê¸°ì‚¬ JSON ì €ì¥ í™•ì¸
    Tool: Bash (python)
    Preconditions: data/ ë””ë ‰í† ë¦¬ ì¡´ì¬
    Steps:
      1. python -c "
         import json, os
         from src.storage import save_daily_articles
         from src.scraper import Article
         articles = [
             Article(source='test', source_id='99', title='Test Article', url='http://test.com', discussion_url='', summary='Test', score=10, published_at='2026-02-10'),
         ]
         save_daily_articles(articles, '2026-02-10')
         path = 'data/2026/02/10.json'
         assert os.path.exists(path), f'{path} not found'
         data = json.load(open(path))
         print(f'Articles saved: {len(data)}')
         print(f'Title: {data[0][\"title\"]}')
         "
      2. Assert: Articles saved == 1
      3. Assert: Title == "Test Article"
      4. ì •ë¦¬: rm -rf data/2026
    Expected Result: ë‚ ì§œë³„ ë””ë ‰í† ë¦¬ì— JSON íŒŒì¼ ì €ì¥ë¨
    Evidence: python ì¶œë ¥ ìº¡ì²˜

  Scenario: seen_ids.json ì •ë ¬ ì €ì¥ í™•ì¸
    Tool: Bash
    Steps:
      1. python -c "
         from src.storage import save_seen_ids
         save_seen_ids({'test:3', 'test:1', 'test:2'})
         "
      2. python -c "import json; data = json.load(open('data/seen_ids.json')); print(data)"
      3. Assert: ì¶œë ¥ì´ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ ['test:1', 'test:2', 'test:3']
    Expected Result: seen_idsê°€ ì •ë ¬ë˜ì–´ ì €ì¥ë¨ (git diff ìµœì†Œí™”)
    Evidence: python ì¶œë ¥ ìº¡ì²˜
  ```

  **Commit**: YES
  - Message: `feat(storage): add JSON storage, deduplication, and GitHub Issues creation`
  - Files: `src/storage.py`
  - Pre-commit: `python -c "from src.storage import load_seen_ids; print('OK')"`

---

- [x] 6. ì•Œë¦¼ ëª¨ë“ˆ (notifier.py)

  **What to do**:
  - `src/notifier.py` êµ¬í˜„:
    - `format_digest(articles: list[Article]) -> str`:
      - í…”ë ˆê·¸ë¨ MarkdownV2 í˜•ì‹ìœ¼ë¡œ ë‹¤ì´ì œìŠ¤íŠ¸ í¬ë§¤íŒ…
      - í—¤ë”: `ğŸ“° InsightFlow Daily Digest - {ë‚ ì§œ}`
      - ì†ŒìŠ¤ë³„ ì„¹ì…˜:
        ```
        ğŸ‡°ğŸ‡· *GeekNews*
        
        1\. *{title}*
        {ai_summary ë˜ëŠ” ê¸°ì¡´ summary}
        ğŸ”— [ì›ë¬¸]({url}) \| [í† ë¡ ]({discussion_url})
        â­ ê´€ë ¨ì„±: {relevance_score}
        
        ğŸŒ *Hacker News*
        
        1\. *{title}* \(â¬†{score}\)
        {ai_summary}
        ğŸ”— [ì›ë¬¸]({url}) \| [í† ë¡ ]({discussion_url})
        ```
      - ê¸°ì‚¬ê°€ ì—†ìœ¼ë©´: `ì˜¤ëŠ˜ì€ ê´€ë ¨ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.`
      - MarkdownV2 íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬ (`_`, `*`, `[`, `]`, `(`, `)`, `~`, `` ` ``, `>`, `#`, `+`, `-`, `=`, `|`, `{`, `}`, `.`, `!`)

    - `chunk_message(text: str, max_length: int = 4096) -> list[str]`:
      - 4,096 UTF-8 ë¬¸ì ì œí•œì— ë§ê²Œ ë©”ì‹œì§€ ë¶„í• 
      - ê¸°ì‚¬ ë‹¨ìœ„ë¡œ ë¶„í•  (ê¸°ì‚¬ ì¤‘ê°„ì—ì„œ ìë¥´ì§€ ì•ŠìŒ)
      - ê° ì²­í¬ ëì— `(1/N)` í˜•ì‹ í˜ì´ì§€ í‘œì‹œ

    - `send_telegram(text: str)`:
      - `requests.post()` ì‚¬ìš© (ê°„ë‹¨í•œ HTTP POST)
      - URL: `https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage`
      - Body: `{"chat_id": TELEGRAM_CHAT_ID, "text": text, "parse_mode": "MarkdownV2"}`
      - 3íšŒ ì¬ì‹œë„ (ì§€ìˆ˜ ë°±ì˜¤í”„: 2s, 6s, 18s)
      - ì—ëŸ¬ ì‹œ ë¡œê¹… + ì˜ˆì™¸ ì „íŒŒ (mainì—ì„œ ì²˜ë¦¬)

    - `send_digest(articles: list[Article])`:
      - `format_digest()` â†’ `chunk_message()` â†’ ê° ì²­í¬ì— `send_telegram()` í˜¸ì¶œ
      - ì²­í¬ ê°„ 1ì´ˆ ëŒ€ê¸° (rate limit ë°©ì§€)

    - `send_failure_notification(error_message: str)`:
      - ì‹¤íŒ¨ ì•Œë¦¼ ì „ìš© í•¨ìˆ˜
      - `âš ï¸ InsightFlow ì‹¤í–‰ ì‹¤íŒ¨\n\n{error_message}\n\n{timestamp}`
      - MarkdownV2 ì´ìŠ¤ì¼€ì´í”„ ì ìš©

  **Must NOT do**:
  - python-telegram-bot ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¸ˆì§€ (ê°„ë‹¨í•œ requestsë¡œ ì¶©ë¶„)
  - ì¸ë¼ì¸ í‚¤ë³´ë“œ/ë²„íŠ¼ ì¶”ê°€ ê¸ˆì§€
  - ì´ë¯¸ì§€/ë¯¸ë””ì–´ ì²¨ë¶€ ê¸ˆì§€
  - HTML íŒŒì‹± ëª¨ë“œ ì‚¬ìš© ê¸ˆì§€ (MarkdownV2 í†µì¼)

  **Recommended Agent Profile**:
  - **Category**: `unspecified-high`
    - Reason: í…”ë ˆê·¸ë¨ API í†µí•©, MarkdownV2 ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬, ë©”ì‹œì§€ ì²­í‚¹ ë¡œì§
  - **Skills**: []
  - **Skills Evaluated but Omitted**:
    - `frontend-ui-ux`: í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í¬ë§¤íŒ…ì´ì§€ UIê°€ ì•„ë‹˜

  **Parallelization**:
  - **Can Run In Parallel**: NO
  - **Parallel Group**: Wave 3 (sequential, before Task 7)
  - **Blocks**: Task 7
  - **Blocked By**: Task 1

  **References**:

  **Pattern References**:
  - `src/config.py` (Task 1) - TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID
  - `src/scraper.py:Article` (Task 3) - Article dataclass êµ¬ì¡°

  **API/Type References**:
  - Telegram Bot API - sendMessage:
    - `POST https://api.telegram.org/bot{token}/sendMessage`
    - Body: `{"chat_id": "...", "text": "...", "parse_mode": "MarkdownV2"}`
    - ì„±ê³µ ì‘ë‹µ: `{"ok": true, "result": {...}}`
    - ì—ëŸ¬ ì‘ë‹µ: `{"ok": false, "error_code": 400, "description": "..."}`
  - MarkdownV2 ì´ìŠ¤ì¼€ì´í”„ í•„ìš” ë¬¸ì: `_*[]()~` `` ` `` `>#+\-=|{}.!`
  - ë©”ì‹œì§€ ìµœëŒ€ ê¸¸ì´: UTF-8 4,096ì

  **External References**:
  - Telegram Bot API sendMessage: https://core.telegram.org/bots/api#sendmessage
  - MarkdownV2 í˜•ì‹: https://core.telegram.org/bots/api#markdownv2-style

  **WHY Each Reference Matters**:
  - MarkdownV2 ì´ìŠ¤ì¼€ì´í”„ê°€ ê¹Œë‹¤ë¡œì›€ - ê³µì‹ ë¬¸ì„œì—ì„œ ì •í™•í•œ ê·œì¹™ í™•ì¸ í•„ìˆ˜
  - 4,096ì ì œí•œ ì´ˆê³¼ ì‹œ API ì—ëŸ¬ ë°œìƒí•˜ë¯€ë¡œ ì²­í‚¹ ë¡œì§ì´ í•µì‹¬

  **Acceptance Criteria**:

  **Agent-Executed QA Scenarios:**

  ```
  Scenario: ë‹¤ì´ì œìŠ¤íŠ¸ í¬ë§¤íŒ… + ê¸¸ì´ ì œí•œ í™•ì¸
    Tool: Bash (python)
    Steps:
      1. python -c "
         from src.scraper import Article
         from src.notifier import format_digest, chunk_message
         articles = [
             Article(source='geeknews', source_id='1', title='AI ê¸°ìˆ  íŠ¸ë Œë“œ', url='http://a.com', discussion_url='http://d.com', summary='ìš”ì•½ í…ŒìŠ¤íŠ¸', score=0, published_at='2026-02-10', ai_summary='AI ìš”ì•½ ê²°ê³¼ì…ë‹ˆë‹¤.', relevance_score=0.9),
         ]
         digest = format_digest(articles)
         print(f'Digest length: {len(digest)}')
         print(f'Contains InsightFlow: {\"InsightFlow\" in digest}')
         chunks = chunk_message(digest)
         print(f'Chunks: {len(chunks)}')
         for i, c in enumerate(chunks):
             print(f'Chunk {i} length: {len(c)}')
             assert len(c) <= 4096, f'Chunk {i} exceeds 4096 chars'
         "
      2. Assert: Digest length > 0
      3. Assert: Contains InsightFlow == True
      4. Assert: ëª¨ë“  ì²­í¬ <= 4096ì
    Expected Result: ë‹¤ì´ì œìŠ¤íŠ¸ê°€ ì˜¬ë°”ë¥´ê²Œ í¬ë§¤íŒ…ë˜ê³  ì²­í¬ ë¶„í• ë¨
    Evidence: python ì¶œë ¥ ìº¡ì²˜

  Scenario: í…”ë ˆê·¸ë¨ ë°œì†¡ ì„±ê³µ (ì‹¤ì œ API)
    Tool: Bash (python)
    Preconditions: .envì— ìœ íš¨í•œ TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID ì„¤ì •ë¨
    Steps:
      1. python -c "
         from src.notifier import send_telegram
         send_telegram('ğŸ§ª InsightFlow í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì…ë‹ˆë‹¤\\.')
         print('SENT')
         "
      2. Assert: "SENT" ì¶œë ¥ (ì—ëŸ¬ ì—†ìŒ)
      3. Assert: í…”ë ˆê·¸ë¨ì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹  í™•ì¸ (send_telegram ë°˜í™˜ê°’ ì²´í¬)
    Expected Result: í…”ë ˆê·¸ë¨ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ë°œì†¡ë¨
    Evidence: python ì¶œë ¥ ìº¡ì²˜

  Scenario: MarkdownV2 íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ í™•ì¸
    Tool: Bash (python)
    Steps:
      1. python -c "
         from src.notifier import format_digest
         from src.scraper import Article
         # íŠ¹ìˆ˜ë¬¸ì í¬í•¨ ì œëª©
         articles = [
             Article(source='hackernews', source_id='1', title='C++ vs Rust: A 2026 Guide (Part 1)', url='http://a.com', discussion_url='http://d.com', summary='', score=150, published_at='2026-02-10', ai_summary='C++ê³¼ Rust ë¹„êµ.', relevance_score=0.7),
         ]
         digest = format_digest(articles)
         # MarkdownV2ì—ì„œ íŒŒì‹± ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ëŠ” ì´ìŠ¤ì¼€ì´í”„ë˜ì§€ ì•Šì€ ë¬¸ìê°€ ì—†ì–´ì•¼ í•¨
         print(f'Contains raw +: {\"+\" in digest and \"\\\\+\" not in digest}')
         print(f'Contains raw .: {\".\" in digest and \"\\\\.\" not in digest}')
         print('Format check passed')
         "
      2. Assert: ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ìƒì„±ë¨
    Expected Result: íŠ¹ìˆ˜ë¬¸ìê°€ MarkdownV2 ê·œê²©ì— ë§ê²Œ ì´ìŠ¤ì¼€ì´í”„ë¨
    Evidence: python ì¶œë ¥ ìº¡ì²˜

  Scenario: ì‹¤íŒ¨ ì•Œë¦¼ ë°œì†¡
    Tool: Bash (python)
    Preconditions: .envì— ìœ íš¨í•œ í…”ë ˆê·¸ë¨ ì„¤ì •
    Steps:
      1. python -c "
         from src.notifier import send_failure_notification
         send_failure_notification('Test error: API connection timeout')
         print('FAILURE NOTIFICATION SENT')
         "
      2. Assert: "FAILURE NOTIFICATION SENT" ì¶œë ¥
    Expected Result: ì‹¤íŒ¨ ì•Œë¦¼ì´ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ë°œì†¡ë¨
    Evidence: python ì¶œë ¥ ìº¡ì²˜
  ```

  **Commit**: YES
  - Message: `feat(notifier): add Telegram digest formatting with message chunking`
  - Files: `src/notifier.py`
  - Pre-commit: `python -c "from src.notifier import send_digest; print('OK')"`

---

- [x] 7. ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (main.py)

  **What to do**:
  - `src/main.py` êµ¬í˜„:
    - CLI ì¸í„°í˜ì´ìŠ¤:
      - `--dry-run` í”Œë˜ê·¸: í…”ë ˆê·¸ë¨ ë°œì†¡ + git ì»¤ë°‹ + GitHub Issues ìŠ¤í‚µ
      - `argparse` ì‚¬ìš© (ê°„ë‹¨í•œ ì¸ì íŒŒì‹±)

    - `main()` í•¨ìˆ˜ - ì „ì²´ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜:
      ```python
      def main(dry_run: bool = False):
          try:
              # 1. ë°ì´í„° ìˆ˜ì§‘
              logger.info("Starting data collection...")
              all_articles = scrape_all()
              logger.info(f"Collected {len(all_articles)} articles")
              
              # 2. ì¤‘ë³µ ì œê±°
              seen_ids = load_seen_ids()
              new_articles = filter_new_articles(all_articles, seen_ids)
              logger.info(f"New articles: {len(new_articles)}")
              
              if not new_articles:
                  logger.info("No new articles found. Exiting.")
                  return
              
              # 3. í‚¤ì›Œë“œ í•„í„° + AI ìš”ì•½
              processed = filter_and_summarize(new_articles)
              logger.info(f"After filtering: {len(processed)} articles")
              
              # 4. ë°ì´í„° ì €ì¥
              today = datetime.now().strftime("%Y-%m-%d")
              save_daily_articles(processed, today)
              save_seen_ids(seen_ids)
              
              # 5. í…”ë ˆê·¸ë¨ ë°œì†¡
              if not dry_run:
                  send_digest(processed)
                  logger.info("Telegram digest sent")
              else:
                  logger.info("[DRY RUN] Telegram send skipped")
              
              # 6. GitHub Issues ìƒì„±
              if not dry_run:
                  create_github_issues(processed)
                  logger.info("GitHub Issues created")
              
              logger.info("Pipeline completed successfully")
              
          except Exception as e:
              logger.error(f"Pipeline failed: {e}")
              if not dry_run:
                  try:
                      send_failure_notification(str(e))
                  except:
                      logger.error("Failed to send failure notification")
              raise
      ```

    - `logging` ì„¤ì •:
      - í¬ë§·: `[%(asctime)s] %(levelname)s - %(message)s`
      - ë ˆë²¨: INFO (ê¸°ë³¸), DEBUG (í™˜ê²½ë³€ìˆ˜ë¡œ ì „í™˜ ê°€ëŠ¥)
      - stdoutìœ¼ë¡œ ì¶œë ¥ (GitHub Actions ë¡œê·¸ì— í‘œì‹œ)

    - `if __name__ == "__main__"` ë¸”ë¡:
      - argparseë¡œ `--dry-run` íŒŒì‹±
      - í™˜ê²½ë³€ìˆ˜ `DRY_RUN=true`ë„ ì§€ì›
      - `main(dry_run=...)` í˜¸ì¶œ

  **Must NOT do**:
  - click/typer ë“± CLI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¸ˆì§€ (argparseë§Œ)
  - ë³µì¡í•œ ë¡œê¹… ì„¤ì • ê¸ˆì§€ (ê¸°ë³¸ loggingë§Œ)
  - ìŠ¤ì¼€ì¤„ëŸ¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¸ˆì§€ (GitHub Actionsê°€ ìŠ¤ì¼€ì¤„ë§)
  - ë°ëª¬/ì„œë¹„ìŠ¤ ëª¨ë“œ ê¸ˆì§€

  **Recommended Agent Profile**:
  - **Category**: `unspecified-high`
    - Reason: ëª¨ë“  ëª¨ë“ˆì„ í†µí•©í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë¡œì§. ì—ëŸ¬ í•¸ë“¤ë§ + ë¡œê¹… + CLI.
  - **Skills**: []
  - **Skills Evaluated but Omitted**:
    - `deep`: í†µí•© ì‘ì—…ì´ì§€ë§Œ ê° ëª¨ë“ˆì´ ì´ë¯¸ ì™„ì„±ë˜ì–´ ìˆìœ¼ë¯€ë¡œ deep ë¶ˆí•„ìš”

  **Parallelization**:
  - **Can Run In Parallel**: NO
  - **Parallel Group**: Wave 3 (after Task 6)
  - **Blocks**: Task 8
  - **Blocked By**: Tasks 3, 4, 5, 6

  **References**:

  **Pattern References**:
  - `src/scraper.py:scrape_all` (Task 3) - ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
  - `src/ai_handler.py:filter_and_summarize` (Task 4) - AI í•„í„°ë§/ìš”ì•½ í•¨ìˆ˜
  - `src/storage.py:load_seen_ids, filter_new_articles, save_seen_ids, save_daily_articles, create_github_issues` (Task 5) - ì €ì¥/ì¤‘ë³µë°©ì§€ í•¨ìˆ˜ë“¤
  - `src/notifier.py:send_digest, send_failure_notification` (Task 6) - ì•Œë¦¼ í•¨ìˆ˜ë“¤

  **WHY Each Reference Matters**:
  - main.pyëŠ” ëª¨ë“  ëª¨ë“ˆì„ í˜¸ì¶œí•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì´ë¯€ë¡œ ê° ëª¨ë“ˆì˜ ê³µê°œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •í™•íˆ ì•Œì•„ì•¼ í•¨
  - ì—ëŸ¬ í•¸ë“¤ë§ íë¦„ì´ ì¤‘ìš”: ì–´ë–¤ ë‹¨ê³„ì—ì„œ ì‹¤íŒ¨í•´ë„ ì´í›„ ë‹¨ê³„ë¥¼ ì ì ˆíˆ ì²˜ë¦¬í•´ì•¼ í•¨

  **Acceptance Criteria**:

  **Agent-Executed QA Scenarios:**

  ```
  Scenario: --dry-run ëª¨ë“œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    Tool: Bash (python)
    Preconditions: .envì— ìœ íš¨í•œ GEMINI_API_KEY ì„¤ì • (í…”ë ˆê·¸ë¨ì€ í•„ìˆ˜ ì•„ë‹˜)
    Steps:
      1. python src/main.py --dry-run 2>&1
      2. Assert: exit code 0
      3. Assert: ì¶œë ¥ì— "Starting data collection" í¬í•¨
      4. Assert: ì¶œë ¥ì— "DRY RUN" í¬í•¨
      5. Assert: ì¶œë ¥ì— "Pipeline completed" ë˜ëŠ” "No new articles" í¬í•¨
      6. Assert: í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ê°€ ë°œì†¡ë˜ì§€ ì•Šì•˜ìŒ (DRY RUN ë¡œê·¸)
    Expected Result: ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ dry-runìœ¼ë¡œ ì—ëŸ¬ ì—†ì´ ì‹¤í–‰ë¨
    Evidence: ì „ì²´ stdout/stderr ìº¡ì²˜

  Scenario: DRY_RUN í™˜ê²½ë³€ìˆ˜ë¡œë„ dry-run ë™ì‘
    Tool: Bash
    Steps:
      1. DRY_RUN=true python src/main.py 2>&1
      2. Assert: ì¶œë ¥ì— "DRY RUN" í¬í•¨
    Expected Result: í™˜ê²½ë³€ìˆ˜ë¡œë„ dry-run ëª¨ë“œ í™œì„±í™”ë¨
    Evidence: stdout ìº¡ì²˜

  Scenario: ë‘ ë²ˆ ì—°ì† ì‹¤í–‰ ì‹œ ì¤‘ë³µ ì—†ìŒ
    Tool: Bash
    Preconditions: data/seen_ids.json ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŒ
    Steps:
      1. rm -f data/seen_ids.json
      2. python src/main.py --dry-run 2>&1
      3. COUNT1=$(python -c "import json; print(len(json.load(open('data/seen_ids.json'))))")
      4. python src/main.py --dry-run 2>&1
      5. Assert: ë‘ ë²ˆì§¸ ì‹¤í–‰ ì¶œë ¥ì— "No new articles" í¬í•¨ ë˜ëŠ” ìƒˆ ê¸°ì‚¬ ìˆ˜ê°€ 0
    Expected Result: ë™ì¼ ê¸°ì‚¬ê°€ ì¤‘ë³µ ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ
    Evidence: ë‘ ì‹¤í–‰ì˜ stdout ìº¡ì²˜

  Scenario: ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë¡œê¹… í™•ì¸
    Tool: Bash
    Steps:
      1. GEMINI_API_KEY=invalid python src/main.py --dry-run 2>&1
      2. Assert: í”„ë¡œê·¸ë¨ì´ ì™„ë£Œë¨ (graceful degradation) ë˜ëŠ” ì—ëŸ¬ ë¡œê·¸ ì¶œë ¥
    Expected Result: ì‹¤íŒ¨í•´ë„ ì ì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€ì™€ í•¨ê»˜ ì¢…ë£Œ
    Evidence: stderr ìº¡ì²˜
  ```

  **Commit**: YES
  - Message: `feat(main): add pipeline orchestrator with dry-run support`
  - Files: `src/main.py`
  - Pre-commit: `python src/main.py --dry-run 2>&1 | head -5`

---

- [x] 8. GitHub Actions ì›Œí¬í”Œë¡œìš° + ìµœì¢… í†µí•©

  **What to do**:
  - `.github/workflows/daily-digest.yml` ìƒì„±:
    ```yaml
    name: InsightFlow Daily Digest

    on:
      schedule:
        - cron: '0 23 * * *'  # ë§¤ì¼ KST 08:00 (UTC 23:00)
      workflow_dispatch:  # ìˆ˜ë™ íŠ¸ë¦¬ê±° ì§€ì›

    concurrency:
      group: daily-digest
      cancel-in-progress: false  # ì§„í–‰ ì¤‘ì¸ ì‹¤í–‰ ì·¨ì†Œí•˜ì§€ ì•ŠìŒ

    permissions:
      contents: write  # JSON íŒŒì¼ ì»¤ë°‹ìš©
      issues: write    # GitHub Issues ìƒì„±ìš©

    jobs:
      run-digest:
        runs-on: ubuntu-latest
        
        steps:
          - name: Checkout Repository
            uses: actions/checkout@v4
            with:
              token: ${{ secrets.GITHUB_TOKEN }}

          - name: Set up Python 3.11
            uses: actions/setup-python@v5
            with:
              python-version: '3.11'
              cache: 'pip'

          - name: Install Dependencies
            run: pip install -r requirements.txt

          - name: Run InsightFlow Pipeline
            env:
              GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
              TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
              TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
              GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
            run: python src/main.py

          - name: Commit Updated Data
            run: |
              git config user.name "InsightFlow Bot"
              git config user.email "insightflow-bot@users.noreply.github.com"
              git add data/
              git diff --staged --quiet || git commit -m "data: daily digest $(date +%Y-%m-%d)"
              git push

          - name: Notify on Failure
            if: failure()
            env:
              TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
              TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
            run: |
              python -c "
              from src.notifier import send_failure_notification
              send_failure_notification('GitHub Actions workflow failed. Check: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}')
              "
    ```

  - ìµœì¢… í†µí•© ê²€ì¦:
    - ëª¨ë“  ëª¨ë“ˆ import í…ŒìŠ¤íŠ¸
    - YAML ë¬¸ë²• ê²€ì¦
    - íŒŒì¼ êµ¬ì¡° í™•ì¸
    - `--dry-run` ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

  **Must NOT do**:
  - Docker ì»¨í…Œì´ë„ˆ ì‚¬ìš© ê¸ˆì§€ (ì§ì ‘ Python ì‹¤í–‰ì´ ë¹ ë¦„)
  - ë³µì¡í•œ ìºì‹± ì „ëµ ê¸ˆì§€ (pip ìºì‹œë§Œ)
  - ë‹¤ë¥¸ ì›Œí¬í”Œë¡œìš° íŒŒì¼ ìƒì„± ê¸ˆì§€ (ë‹¨ì¼ ì›Œí¬í”Œë¡œìš°)
  - main ë¸Œëœì¹˜ ì™¸ ë°°í¬ ì „ëµ ê¸ˆì§€

  **Recommended Agent Profile**:
  - **Category**: `deep`
    - Reason: GitHub Actions YAML + ìµœì¢… í†µí•© í…ŒìŠ¤íŠ¸. ëª¨ë“  ëª¨ë“ˆì´ ì˜¬ë°”ë¥´ê²Œ ì—°ë™ë˜ëŠ”ì§€ ì‹¬ì¸µ ê²€ì¦ í•„ìš”.
  - **Skills**: []
  - **Skills Evaluated but Omitted**:
    - `git-master`: Git ì„¤ì •ì€ YAML ì•ˆì—ì„œ í•˜ë¯€ë¡œ ì§ì ‘ì  git ì‘ì—… ì•„ë‹˜

  **Parallelization**:
  - **Can Run In Parallel**: NO
  - **Parallel Group**: Wave 4 (final)
  - **Blocks**: None (final task)
  - **Blocked By**: Tasks 2, 7

  **References**:

  **Pattern References**:
  - `src/main.py` (Task 7) - íŒŒì´í”„ë¼ì¸ ì§„ì…ì 
  - `src/notifier.py:send_failure_notification` (Task 6) - ì‹¤íŒ¨ ì•Œë¦¼ í•¨ìˆ˜

  **API/Type References**:
  - GitHub Actions ì»¨í…ìŠ¤íŠ¸ ë³€ìˆ˜: `${{ secrets.* }}`, `${{ github.repository }}`, `${{ github.run_id }}`
  - `actions/checkout@v4` - `token` íŒŒë¼ë¯¸í„°ë¡œ push ê¶Œí•œ í™•ë³´
  - `actions/setup-python@v5` - `cache: 'pip'`ìœ¼ë¡œ ì˜ì¡´ì„± ìºì‹±

  **External References**:
  - GitHub Actions workflow ë¬¸ë²•: https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions
  - GitHub Actions schedule íŠ¸ë¦¬ê±°: https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#schedule
  - actions/checkout: https://github.com/actions/checkout
  - actions/setup-python: https://github.com/actions/setup-python

  **WHY Each Reference Matters**:
  - `concurrency` ì„¤ì •ìœ¼ë¡œ ë™ì‹œ ì‹¤í–‰ ë°©ì§€ê°€ í•µì‹¬ (ìˆ˜ë™ + í¬ë¡  ë™ì‹œ ì‹¤í–‰ ì‹œ git push ì¶©ëŒ)
  - `permissions` ì„¤ì •ìœ¼ë¡œ GITHUB_TOKENì— ì˜¬ë°”ë¥¸ ê¶Œí•œ ë¶€ì—¬ í•„ìˆ˜
  - `if: failure()` ì¡°ê±´ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ ì‹œì—ë§Œ ì•Œë¦¼ ë°œì†¡

  **Acceptance Criteria**:

  **Agent-Executed QA Scenarios:**

  ```
  Scenario: GitHub Actions YAML ìœ íš¨ì„± ê²€ì¦
    Tool: Bash (python)
    Steps:
      1. python -c "
         import yaml
         with open('.github/workflows/daily-digest.yml') as f:
             config = yaml.safe_load(f)
         print(f'Name: {config[\"name\"]}')
         print(f'Has schedule: {\"schedule\" in config[\"on\"]}')
         print(f'Has workflow_dispatch: {\"workflow_dispatch\" in config[\"on\"]}')
         print(f'Has concurrency: {\"concurrency\" in config}')
         print(f'Permissions: {config.get(\"permissions\", {})}')
         cron = config['on']['schedule'][0]['cron']
         print(f'Cron: {cron}')
         "
      2. Assert: Name == "InsightFlow Daily Digest"
      3. Assert: Has schedule == True
      4. Assert: Has workflow_dispatch == True
      5. Assert: Has concurrency == True
      6. Assert: Permissionsì— contents: write, issues: write í¬í•¨
      7. Assert: Cron == "0 23 * * *"
    Expected Result: YAMLì´ ì˜¬ë°”ë¥´ê²Œ íŒŒì‹±ë˜ê³  ëª¨ë“  í•„ìˆ˜ ì„¤ì • í¬í•¨
    Evidence: python ì¶œë ¥ ìº¡ì²˜

  Scenario: ì „ì²´ ëª¨ë“ˆ import ì„±ê³µ
    Tool: Bash (python)
    Steps:
      1. python -c "
         from src.config import KEYWORDS, GEEKNEWS_RSS_URL
         from src.scraper import scrape_all, Article
         from src.ai_handler import filter_and_summarize
         from src.storage import load_seen_ids, save_seen_ids, filter_new_articles, save_daily_articles
         from src.notifier import send_digest, send_failure_notification
         print('All imports successful')
         "
      2. Assert: "All imports successful" ì¶œë ¥
    Expected Result: ëª¨ë“  ëª¨ë“ˆì´ ì—ëŸ¬ ì—†ì´ importë¨
    Evidence: python ì¶œë ¥ ìº¡ì²˜

  Scenario: ì „ì²´ íŒŒì¼ êµ¬ì¡° í™•ì¸
    Tool: Bash
    Steps:
      1. test -f .github/workflows/daily-digest.yml && echo "WORKFLOW OK"
      2. test -f src/__init__.py && echo "INIT OK"
      3. test -f src/main.py && echo "MAIN OK"
      4. test -f src/scraper.py && echo "SCRAPER OK"
      5. test -f src/ai_handler.py && echo "AI OK"
      6. test -f src/storage.py && echo "STORAGE OK"
      7. test -f src/notifier.py && echo "NOTIFIER OK"
      8. test -f src/config.py && echo "CONFIG OK"
      9. test -f requirements.txt && echo "REQUIREMENTS OK"
      10. test -f .env.example && echo "ENV OK"
      11. test -f README.md && echo "README OK"
      12. test -d data && echo "DATA DIR OK"
    Expected Result: ëª¨ë“  12ê°œ í•­ëª© OK
    Evidence: ëª…ë ¹ ì¶œë ¥ ìº¡ì²˜

  Scenario: ì „ì²´ íŒŒì´í”„ë¼ì¸ dry-run (ìµœì¢… í†µí•© í…ŒìŠ¤íŠ¸)
    Tool: Bash
    Preconditions: .envì— ìœ íš¨í•œ GEMINI_API_KEY ì„¤ì •
    Steps:
      1. python src/main.py --dry-run 2>&1
      2. Assert: exit code 0
      3. Assert: ì¶œë ¥ì— "Pipeline completed" ë˜ëŠ” "No new articles" í¬í•¨
      4. ls data/ í™•ì¸
      5. Assert: data/ ì•„ë˜ì— JSON íŒŒì¼ ë˜ëŠ” seen_ids.json ì¡´ì¬
    Expected Result: ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ë¡œì»¬ì—ì„œ ì—ëŸ¬ ì—†ì´ ì™„ë£Œë¨
    Evidence: ì „ì²´ stdout/stderr + data/ íŒŒì¼ ëª©ë¡ ìº¡ì²˜
  ```

  **Commit**: YES
  - Message: `ci: add GitHub Actions daily digest workflow with failure notifications`
  - Files: `.github/workflows/daily-digest.yml`
  - Pre-commit: `python -c "import yaml; yaml.safe_load(open('.github/workflows/daily-digest.yml')); print('VALID')"`

---

## Commit Strategy

| After Task | Message | Files | Verification |
|------------|---------|-------|--------------|
| 1 | `feat(config): add project setup with config module and dependencies` | requirements.txt, .env.example, src/__init__.py, src/config.py, data/.gitkeep | `python -c "from src.config import KEYWORDS; print('OK')"` |
| 2 | `docs: add README with architecture diagram and setup guide` | README.md | `test -f README.md` |
| 3 | `feat(scraper): add GeekNews Atom feed and HN API data collection` | src/scraper.py | `python -c "from src.scraper import scrape_all; print('OK')"` |
| 4 | `feat(ai): add Gemini batch summarization with keyword filtering` | src/ai_handler.py | `python -c "from src.ai_handler import filter_and_summarize; print('OK')"` |
| 5 | `feat(storage): add JSON storage, deduplication, and GitHub Issues creation` | src/storage.py | `python -c "from src.storage import load_seen_ids; print('OK')"` |
| 6 | `feat(notifier): add Telegram digest formatting with message chunking` | src/notifier.py | `python -c "from src.notifier import send_digest; print('OK')"` |
| 7 | `feat(main): add pipeline orchestrator with dry-run support` | src/main.py | `python src/main.py --dry-run` |
| 8 | `ci: add GitHub Actions daily digest workflow with failure notifications` | .github/workflows/daily-digest.yml | `python -c "import yaml; yaml.safe_load(open('.github/workflows/daily-digest.yml')); print('VALID')"` |

---

## Success Criteria

### Verification Commands
```bash
# ì „ì²´ ëª¨ë“ˆ import í™•ì¸
python -c "from src.config import *; from src.scraper import *; from src.ai_handler import *; from src.storage import *; from src.notifier import *; print('ALL IMPORTS OK')"

# dry-run ì „ì²´ íŒŒì´í”„ë¼ì¸
python src/main.py --dry-run  # Expected: exit code 0, "Pipeline completed" in output

# ì¤‘ë³µ ë°©ì§€ í™•ì¸ (ë‘ ë²ˆ ì‹¤í–‰)
python src/main.py --dry-run && python src/main.py --dry-run  # Expected: ë‘ ë²ˆì§¸ ì‹¤í–‰ì—ì„œ ìƒˆ ê¸°ì‚¬ 0ê°œ

# YAML ìœ íš¨ì„±
python -c "import yaml; yaml.safe_load(open('.github/workflows/daily-digest.yml')); print('VALID')"

# íŒŒì¼ êµ¬ì¡° ì™„ì „ì„±
ls -la src/main.py src/scraper.py src/ai_handler.py src/storage.py src/notifier.py src/config.py .github/workflows/daily-digest.yml README.md requirements.txt .env.example
```

### Final Checklist
- [ ] All "Must Have" present (11ê°œ í•­ëª©)
- [ ] All "Must NOT Have" absent (12ê°œ ê°€ë“œë ˆì¼)
- [ ] ì „ì²´ íŒŒì´í”„ë¼ì¸ `--dry-run` ì„±ê³µ
- [ ] GitHub Actions YAML ìœ íš¨
- [ ] READMEì— ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ + ë¡œì»¬ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ í¬í•¨
- [ ] í…”ë ˆê·¸ë¨ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ë°œì†¡ ì„±ê³µ
- [ ] ì¤‘ë³µ ì‹¤í–‰ ì‹œ ë°ì´í„° ì¤‘ë³µ ì—†ìŒ
- [ ] Gemini API í˜¸ì¶œ íšŸìˆ˜ < 20 per run (ë°°ì¹­ íš¨ê³¼)
